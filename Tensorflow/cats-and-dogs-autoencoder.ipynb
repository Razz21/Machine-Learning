{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Dense,Flatten,Conv2D,Input,MaxPooling2D,Dropout\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nstyle.use('ggplot')\n%matplotlib notebook\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9a07b4deeaee2ffccfb45c414ccdc6eeb389cff"},"cell_type":"code","source":"base_dir = '../input/dataset/dataset'\n\n#train autoencoder files\ntrain_dir = os.path.join(base_dir,'training_set')\n\n#train classification model files\ntest_dir = os.path.join(base_dir,'test_set')\n\ntrain_cats = os.path.join(train_dir,'cats')\ntrain_dogs = os.path.join(train_dir,'dogs')\n\ntest_cats = os.path.join(test_dir,'cats')\ntest_dogs = os.path.join(test_dir,'dogs')\n\n#get filenames\ntrain_cats_fnames = os.listdir(train_cats)\ntrain_dogs_fnames = os.listdir(train_dogs)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"#visualize sample images\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\npic = [os.path.join(train_cats, train_cats_fnames[0])]\npic2 = [os.path.join(train_dogs, train_dogs_fnames[0])]\n\nfor i, img in enumerate(pic + pic2):\n    ax = plt.subplot(1,2,i+1)\n    image = mpimg.imread(img)\n    ax.axis('off')\n    plt.imshow(image)\n    print(image.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad14c6c25bc76ce73761e672d7177c1c1f76d771"},"cell_type":"markdown","source":"# Autoencoder "},{"metadata":{"trusted":true,"_uuid":"c57a48606cd3397b1e82117c782283656e049c20"},"cell_type":"code","source":"input_img = Input(shape=(152,152, 3)) #RGB image\n\n#encoder\nx = Conv2D(16,(3,3),activation='relu',padding='same',)(input_img)\nx = MaxPooling2D(2,padding='same')(x)\nx = Conv2D(8,(3,3),activation='relu',padding='same')(x)\nx = MaxPooling2D(2,padding='same')(x)\nx = Conv2D(8,(3,3),activation='relu',padding='same')(x)\nencoded = MaxPooling2D(2,padding='same')(x)\n\n# at this point the representation is (19, 19, 8)\n\n#decoder\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = keras.layers.UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = keras.layers.UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu',padding='same')(x)\nx = keras.layers.UpSampling2D((2, 2))(x)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder=Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c65a83a241761d233ec4ed8c305b9574ccdd6b1e"},"cell_type":"code","source":"autoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49183f07838606fd480f5893e50e2ba6cc8fc8c7"},"cell_type":"code","source":"# use all files in 'training' directory data to train autoencoder\n# augment train data\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain = ImageDataGenerator(rescale=1./255,\n                          rotation_range=40, \n                          width_shift_range=0.2,\n                          height_shift_range=0.2, \n                          shear_range=.2)\n\ntrain_gen = train.flow_from_directory(train_dir,\n                                    target_size=(152,152),\n                                    batch_size=40,\n                                    class_mode=None,\n                                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49183f07838606fd480f5893e50e2ba6cc8fc8c7","scrolled":true},"cell_type":"code","source":"#use \"test\" directory to train classification model\n\ntest = ImageDataGenerator(rescale=1./255, \n                          validation_split=.4) # split data to train/validation subsets\n\ntrain_generator = test.flow_from_directory(test_dir,\n                                  target_size=(152,152),\n                                  batch_size=10,\n                                  class_mode='binary',\n                                  subset='training'\n)\ntest_generator = test.flow_from_directory(test_dir,\n                                  target_size=(152,152),\n                                  batch_size=10,\n                                  class_mode='binary',\n                                  subset='validation'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"55d45ec875fd02c58a2bc84ff968ffde42649357"},"cell_type":"code","source":"#fit autoencoder model with training data\n\n \ndef fixed_generator(generator): # autoencoder don't feed labels, but 'fit_generator' need x,y values\n    for batch in generator:\n        yield (batch, batch)\n\nhist = autoencoder.fit_generator(\n    fixed_generator(train_gen),\n    epochs = 10,\n    steps_per_epoch=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc3fb30e71ba79af6619df94f217faa2e80b44f0"},"cell_type":"code","source":"#compare original images with reconstructions\n%matplotlib inline\nn = 10\nx = train_gen.next()\ndecoded_imgs = autoencoder.predict(x)\n\n\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n#     # display original\n    ax = plt.subplot(2, n, i+1)\n    image = x[i]\n    plt.imshow(image.reshape(152, 152, 3)) #RGB image\n    ax.axis('off')\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, n + i + 1)\n    plt.imshow(decoded_imgs[i].reshape(152, 152, 3))#RGB image\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d86448defb2adbbb1c1d882636f9c1a87423944"},"cell_type":"code","source":"#visualize activations\n\ntry:\n    layer_outputs = [layer.output for layer in autoencoder.layers[1:2]]\n    activation_model = Model(inputs=autoencoder.input, outputs=layer_outputs)\n    activations = activation_model.predict(x)\nexcept:\n    pass #avoid any errors\n\nn = activations.shape[-1]\n\nfig=plt.figure(figsize=(8, 8))\nrows = 4\ncolumns = n//rows\nfor i in range(n):\n    fig.add_subplot(rows, columns, i+1)\n    plt.imshow(activations[0, :, :, i])\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bea2af59ddc9fb5f7c7dfebf8de01ed988891025"},"cell_type":"markdown","source":"# classification model"},{"metadata":{"trusted":true,"_uuid":"f8cc96c70069284174cbe826db1f84f663d4292d"},"cell_type":"code","source":"#encoder \ninput_img = Input(shape=(152,152, 3)) #RGB image\n\n#same encoder part\nx = Conv2D(16,(3,3),activation='relu',padding='same',)(input_img)\nx = MaxPooling2D(2,padding='same')(x)\nx = Conv2D(8,(3,3),activation='relu',padding='same')(x)\nx = MaxPooling2D(2,padding='same')(x)\nx = Conv2D(8,(3,3),activation='relu',padding='same')(x)\nencoded = MaxPooling2D(2,padding='same')(x)\n\n# fully connected layer with output\nmodel = Flatten()(encoded)\nmodel = Dense(1024, activation='elu')(model)\nmodel = keras.layers.BatchNormalization()(model)\nmodel = Dropout(0.5)(model)\nmodel = Dense(1,activation='sigmoid')(model) #output\n\nfull_model = Model(input_img, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e70aad6ea6269ef39efacb9e3ce5c6ea4ec87c27"},"cell_type":"code","source":"# copy encoder-model weights \n\nfor l1,l2 in zip(full_model.layers[:7],autoencoder.layers[0:7]):\n    l1.set_weights(l2.get_weights())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f502e2b56a30fd7a2fb5760ac94fda8c2bb64f9"},"cell_type":"code","source":"#froze encoder layers\n\nfor layer in full_model.layers[0:7]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0fbd45ab11f0548653d8f60e018a175edf6dd3d"},"cell_type":"code","source":"full_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fab5358657bd1ed408174288854567d23d94062a"},"cell_type":"code","source":"full_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0116a0cd2f4b425ba06c85e515973d94e805bd3b"},"cell_type":"code","source":"callbacks =keras.callbacks.EarlyStopping(monitor='val_loss',\n                                        patience=20, \n                                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"768e768cecbbebfeed442eedb80664f97a89a081"},"cell_type":"code","source":"hist = full_model.fit_generator(train_generator,\n                                     epochs=100,\n                                     steps_per_epoch=100,\n                                     validation_data=test_generator,\n                                     validation_steps=100,\n                                     callbacks=[callbacks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c24974f0947b8faefc42c6d2ee03191c21590f8"},"cell_type":"code","source":"from matplotlib import style\nstyle.use('dark_background')\n%matplotlib inline\ndef show_results(hists):\n    for i,hist in enumerate(hists):\n        plt.figure(figsize=(12,6))\n        plt.subplot(len(hists),2,1)\n        acc = hist.history['acc']\n        test_acc = hist.history['val_acc']\n        loss=hist.history['loss']\n        test_loss=hist.history['val_loss']\n        epochs=range(len(acc))\n        plt.plot(epochs,test_acc,label='test')\n        plt.plot(epochs,acc,label='train')\n        plt.axhline(y=max(test_acc), linestyle='--')\n        plt.legend()\n        plt.title('Accuracy_{}'.format(i))\n        plt.subplot(len(hists),2,2)\n        plt.plot(epochs,test_loss,label='test')\n        plt.plot(epochs,loss,label='train')\n        plt.axhline(y=min(test_loss),linestyle='--')\n        plt.legend()\n        plt.title('Loss_{}'.format(i))\nshow_results([hist])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d5600f8e2cc99683dcf7c6c852de0706dcb5d09"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}